{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPS7mqQc92mW"
      },
      "source": [
        "This notebook is ued to train and evaluate OncoPlex on the pan cancer dataset\n",
        "\n",
        "- Load the data preprocessed previously\n",
        "- Model class\n",
        "- Train and eval functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "772aaQAg35BO"
      },
      "outputs": [],
      "source": [
        "#!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UjEkXghT37l0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv, ChebConv, GATConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score, roc_curve, precision_recall_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RNKVkJ-eY_"
      },
      "source": [
        "# 1- Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDKZgGIzAlw1",
        "outputId": "eddaf0be-3de4-44e9-b8ba-66e2f49c96cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1116, 753)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read my data\n",
        "with open('/content/drive/MyDrive/DTGNN/Cancer data/TCGA/processed/TDHGNN_FI13560.pkl', 'rb') as f:\n",
        "    data= pickle.load(f)\n",
        "\n",
        "data.keys()\n",
        "\n",
        "cancer_nodes = [nodes for nodes, label in zip(data['nodes'], data['label']) if label == 1]\n",
        "len(cancer_nodes)\n",
        "\n",
        "nc_nodes = [nodes for nodes, label in zip(data['nodes'], data['label']) if label == 0]\n",
        "len(nc_nodes), len(cancer_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCkj1xgo_DN5"
      },
      "source": [
        "# 2- Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BmmMpbjj4JsK"
      },
      "outputs": [],
      "source": [
        "# Evaluation metrics\n",
        "def cal_auc(y_true, y_pred):\n",
        "     pred = y_pred.cpu().detach().numpy()\n",
        "     pred= np.exp(pred)\n",
        "     pred = pred[:,1]\n",
        "    # pred = (torch.sigmoid(y_pred) > 0.5).float()\n",
        "     true = y_true.cpu().numpy()\n",
        "     AUROC = roc_auc_score(true, pred)\n",
        "     precision, recall, thresholds = precision_recall_curve(true, pred)\n",
        "     AUPRC = auc(recall, precision)\n",
        "     return AUROC, AUPRC\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "   # pred=(torch.sigmoid(y_pred)>0.5).float()\n",
        "    pred=torch.argmax(y_pred,dim=1).cpu().numpy()\n",
        "    true=y_true.cpu().numpy()\n",
        "    acc = (pred == true).mean()\n",
        "    return acc\n",
        "\n",
        "\n",
        "def f1_score_(y_true, y_pred):\n",
        "    pred = y_pred.cpu().detach().numpy()\n",
        "    pred = np.exp(pred)\n",
        "    pred = (pred[:,1] > 0.5).astype(float)\n",
        "    true = y_true.cpu().numpy()\n",
        "    f1 = f1_score(true, pred)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkfFdMfYZwqg"
      },
      "outputs": [],
      "source": [
        "class conv_layer(nn.Module):\n",
        "    def __init__(self, in_ft, out_ft, bias=True):\n",
        "        super(conv_layer, self).__init__()\n",
        "\n",
        "        self.weight = Parameter(torch.Tensor(in_ft, out_ft))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_ft))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, G: torch.Tensor):\n",
        "        x = x.matmul(self.weight)\n",
        "        if self.bias is not None:\n",
        "            x = x + self.bias\n",
        "        x = G.matmul(x)\n",
        "        return x\n",
        "\n",
        "#===========================================================\n",
        "class HGCN_layer(nn.Module):\n",
        "    def __init__(self, n_hid):\n",
        "        super(HGCN_layer, self).__init__()\n",
        "        self.hgc1 = conv_layer(n_hid, n_hid)\n",
        "        self.act = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x, G):\n",
        "        x = self.hgc1(x, G)\n",
        "        x = self.act(x)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        return x\n",
        "\n",
        "#=======================================================\n",
        "class HD_sim(nn.Module):\n",
        "    def __init__(self, h_dim, dropout=0.5):\n",
        "        super(HD_sim, self).__init__()\n",
        "        self.HD1 = HGCN_layer(h_dim)\n",
        "        self.emb = nn.Linear(h_dim, h_dim)\n",
        "        #self.norm = nn.LayerNorm(h_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, G):\n",
        "        x = F.leaky_relu_(self.HD1(x, G))\n",
        "        x1 = self.emb(x)\n",
        "        #x1 = self.norm(x1)\n",
        "        x1 += x  # residual\n",
        "        return x1\n",
        "\n",
        "#=============================================================\n",
        "class OncoNet(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim, out_dim, num_layer=3, dropout=0.5):\n",
        "        super(OncoNet, self).__init__()\n",
        "\n",
        "        \n",
        "        self.mlp = nn.Linear(in_dim, hid_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList([HD_sim(hid_dim, dropout) for _ in range(num_layer)])\n",
        "        self.fc2 = nn.Linear(hid_dim, out_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, G):\n",
        "        x = F.leaky_relu(self.mlp(x))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, G)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAkRsWVA-zP4"
      },
      "source": [
        "# 2- Pan cancer training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Argument Parser ===\n",
        "parser = argparse.ArgumentParser(description=\"Train OncoPlex model for pan cancer.\")\n",
        "parser.add_argument(\"--seed\", type=int, default=42)\n",
        "parser.add_argument(\"--num_epochs\", type=int, default=300)\n",
        "parser.add_argument(\"--patience\", type=int, default=20, help=\"Early stopping patience\")\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "random.seed(args.seed)\n",
        "\n",
        "# === Load data ===\n",
        "x = torch.tensor(data['comp_features'])\n",
        "y = torch.tensor(data['label'], dtype=torch.long)\n",
        "G = torch.tensor(data['edge_index'], dtype=torch.float)\n",
        "known_idx = data['known_idx']\n",
        "unknown_idx = data['unknown_idx']\n",
        "nodes = data['nodes']\n",
        "\n",
        "param_grid = {\n",
        "    'lr': [0.001, 0.005, 0.0005],\n",
        "    'weight_decay': [0.001, 0.0001],\n",
        "    'hidden_dim': [128, 64, 256],\n",
        "    'dropout': [0.5, 0.4, 0.25],\n",
        "    'num_layers': [2, 3, 4],\n",
        "    'class_weight': [[1.0, 0.4], [1.0, 0.2]]\n",
        "}\n",
        "\n",
        "outer_k = 5\n",
        "inner_k = 3\n",
        "\n",
        "def train(train_idx, weight):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(x, G)\n",
        "    loss = F.nll_loss(logits[train_idx], y[train_idx], weight=torch.tensor(weight))\n",
        "    train_auroc, train_auprc = cal_auc(y[train_idx], logits[train_idx])\n",
        "    train_f1 = f1_score_(y[train_idx], logits[train_idx])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item(), train_auroc, train_auprc, train_f1\n",
        "\n",
        "@torch.no_grad()\n",
        "def val(val_idx, weight):\n",
        "    model.eval()\n",
        "    logits = model(x, G)\n",
        "    loss = F.nll_loss(logits[val_idx], y[val_idx], weight=torch.tensor(weight))\n",
        "    val_acc = accuracy_fn(y[val_idx], logits[val_idx])\n",
        "    val_auroc, val_auprc = cal_auc(y[val_idx], logits[val_idx])\n",
        "    val_f1 = f1_score_(y[val_idx], logits[val_idx])\n",
        "    return loss.item(), val_acc, val_auroc, val_auprc, val_f1\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(test_idx, weight):\n",
        "    model.eval()\n",
        "    logits = model(x, G)\n",
        "    loss = F.nll_loss(logits[test_idx], y[test_idx], weight=torch.tensor(weight))\n",
        "    test_acc = accuracy_fn(y[test_idx], logits[test_idx])\n",
        "    test_auroc, test_auprc = cal_auc(y[test_idx], logits[test_idx])\n",
        "    test_f1 = f1_score_(y[test_idx], logits[test_idx])\n",
        "\n",
        "    test_genes = [nodes[i] for i in test_idx]\n",
        "    unknown_genes = [nodes[i] for i in unknown_idx]\n",
        "\n",
        "    prob_test = logits.exp().detach().cpu().numpy()[test_idx]\n",
        "    prob_unknown = logits.exp().detach().cpu().numpy()[unknown_idx]\n",
        "\n",
        "    test_results = pd.DataFrame(prob_test, index=test_genes, columns=[\"non_driver\", \"driver\"])\n",
        "    unknown_results = pd.DataFrame(prob_unknown, index=unknown_genes, columns=[\"non_driver\", \"driver\"])\n",
        "    final_results = pd.concat([test_results, unknown_results])\n",
        "\n",
        "    return loss.item(), test_acc, test_auroc, test_auprc, test_f1, final_results, test_results, unknown_results\n",
        "\n",
        "# === Outer Cross-Validation ===\n",
        "outer_kfold = StratifiedKFold(n_splits=outer_k, shuffle=True, random_state=args.seed)\n",
        "outer_results = []\n",
        "\n",
        "for fold, (train_val_idx, test_idx) in enumerate(outer_kfold.split(x[known_idx], y[known_idx])):\n",
        "    print(f\"\\n=== Outer Fold {fold + 1}/{outer_k} ===\")\n",
        "\n",
        "    actual_train_val_idx = known_idx[train_val_idx]\n",
        "    actual_test_idx = known_idx[test_idx]\n",
        "\n",
        "    best_hyperparams = None\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    inner_kfold = StratifiedKFold(n_splits=inner_k, shuffle=True, random_state=args.seed)\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        val_losses = []\n",
        "\n",
        "        for inner_train_idx, inner_val_idx in inner_kfold.split(x[actual_train_val_idx], y[actual_train_val_idx]):\n",
        "            train_idx = actual_train_val_idx[inner_train_idx]\n",
        "            val_idx = actual_train_val_idx[inner_val_idx]\n",
        "\n",
        "            model = OncoNet(\n",
        "                x.shape[1],\n",
        "                hid_dim=params['hidden_dim'],\n",
        "                num_layer=params['num_layers'],\n",
        "                dropout=params['dropout'],\n",
        "                out_dim=2\n",
        "            )\n",
        "            optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
        "\n",
        "            best_inner_val_loss = float('inf')\n",
        "            patience_counter = 0\n",
        "\n",
        "            for epoch in range(args.num_epochs):\n",
        "                train_loss, *_ = train(train_idx, weight=params['class_weight'])\n",
        "                val_loss, *_ = val(val_idx, weight=params['class_weight'])\n",
        "\n",
        "                if val_loss < best_inner_val_loss:\n",
        "                    best_inner_val_loss = val_loss\n",
        "                    patience_counter = 0\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "                    if patience_counter >= args.patience:\n",
        "                        print(f\"  Early stopping at epoch {epoch + 1} in inner fold (no improvement for {args.patience} epochs)\")\n",
        "                        break\n",
        "\n",
        "            val_losses.append(best_inner_val_loss)\n",
        "\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_hyperparams = params\n",
        "\n",
        "    print(f\"Best hyperparameters for fold {fold + 1}: {best_hyperparams}\")\n",
        "\n",
        "    # Train with best hyperparameters on full train_val\n",
        "    model = OncoNet(\n",
        "        x.shape[1],\n",
        "        hid_dim=best_hyperparams['hidden_dim'],\n",
        "        num_layer=best_hyperparams['num_layers'],\n",
        "        dropout=best_hyperparams['dropout'],\n",
        "        out_dim=2\n",
        "    )\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=best_hyperparams['lr'], weight_decay=best_hyperparams['weight_decay'])\n",
        "\n",
        "    for epoch in range(args.num_epochs):\n",
        "        train_loss, *_ = train(actual_train_val_idx, weight=best_hyperparams['class_weight'])\n",
        "\n",
        "    test_loss, test_acc, test_auroc, test_auprc, test_f1, final_results, test_results, unknown_results = test(actual_test_idx, weight=best_hyperparams['class_weight'])\n",
        "\n",
        "    outer_results.append({\n",
        "        'test_loss': test_loss,\n",
        "        'test_acc': test_acc,\n",
        "        'test_auroc': test_auroc,\n",
        "        'test_auprc': test_auprc,\n",
        "        'test_f1': test_f1\n",
        "    })\n",
        "\n",
        "    fold_dir = f\"results/pan_cancer/fold_{fold+1}\"\n",
        "    os.makedirs(fold_dir, exist_ok=True)\n",
        "    test_results.to_csv(f\"{fold_dir}/test_results.csv\")\n",
        "    unknown_results.to_csv(f\"{fold_dir}/unknown_results.csv\")\n",
        "    final_results.to_csv(f\"{fold_dir}/final_results.csv\")\n",
        "\n",
        "# === Save summary ===\n",
        "metrics_df = pd.DataFrame(outer_results)\n",
        "mean_metrics = metrics_df.mean()\n",
        "std_metrics = metrics_df.std()\n",
        "\n",
        "summary_df = pd.DataFrame({\n",
        "    \"Metric\": mean_metrics.index,\n",
        "    \"Mean\": mean_metrics.values,\n",
        "    \"Std\": std_metrics.values\n",
        "})\n",
        "summary_dir = \"results/pan_cancer\"\n",
        "os.makedirs(summary_dir, exist_ok=True)\n",
        "summary_df.to_csv(os.path.join(summary_dir, \"outer_fold_summary.csv\"), index=False)\n",
        "\n",
        "print(\"\\nAverage Results Across Outer Folds:\")\n",
        "print(summary_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
